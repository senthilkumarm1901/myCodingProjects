{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2235da02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded compatibility table\u001b[0m\n",
      "\u001b[1m\n",
      "================= Installed pipeline packages (spaCy v3.3.0) =================\u001b[0m\n",
      "\u001b[38;5;4mℹ spaCy installation: /opt/conda/lib/python3.7/site-packages/spacy\u001b[0m\n",
      "\n",
      "NAME              SPACY                 VERSION                            \n",
      "en_core_web_sm    >=3.3.0.dev0,<3.4.0   \u001b[38;5;2m3.3.0\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
      "en_core_web_trf   >=3.3.0.dev0,<3.4.0   \u001b[38;5;2m3.3.0\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76486f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import pandas as pd\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b28ab3",
   "metadata": {},
   "source": [
    "### Load Dataset from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "935447ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f2f2f7dbcb4ca79eecfed8d1b798cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.83k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset ncbi_disease/ncbi_disease to /path/to/dir/.cache/huggingface/datasets/lewtun___ncbi_disease/ncbi_disease/1.0.0/92314c7992b0b8a5ea2ad101be33f365b684a2cc011e0ffa29c691e6d32b2d03...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c73003e765744771a60374b1f0680721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd7b121509a24a6fb70df0243631b4d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/284k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf310afcffd41d4a25e300dc60e6c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/51.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2617f63d5a4d4663959348caf6dce436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/52.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc936f3b2ee54c3fa4bcafa57d5e0abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ncbi_disease downloaded and prepared to /path/to/dir/.cache/huggingface/datasets/lewtun___ncbi_disease/ncbi_disease/1.0.0/92314c7992b0b8a5ea2ad101be33f365b684a2cc011e0ffa29c691e6d32b2d03. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad199caec86c4714b737dbcf63d07a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_builder = load_dataset(\"lewtun/autoevaluate__ncbi_disease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "325a4155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'tokens', 'ner_tags'],\n",
      "        num_rows: 5433\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'tokens', 'ner_tags'],\n",
      "        num_rows: 924\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'tokens', 'ner_tags'],\n",
      "        num_rows: 941\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbefda70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'tokens': ['Identification',\n",
       "  'of',\n",
       "  'APC2',\n",
       "  ',',\n",
       "  'a',\n",
       "  'homologue',\n",
       "  'of',\n",
       "  'the',\n",
       "  'adenomatous',\n",
       "  'polyposis',\n",
       "  'coli',\n",
       "  'tumour',\n",
       "  'suppressor',\n",
       "  '.'],\n",
       " 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_builder['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e19ea058",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tagging_dict = {0: 'O',\n",
    "                    1: 'B-Disease',\n",
    "                    2: 'I-Disease'\n",
    "                   }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1a0192",
   "metadata": {},
   "source": [
    "### 1.Prepare Spacy_Tokenized_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26ca4513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hf_dataset_2_token_tag_df(hf_dataset):\n",
    "    token_tag_tuple_list = [] \n",
    "    for each in range(len(hf_dataset)):\n",
    "        ids_list = [int(hf_dataset[each]['id']) for every in range(len(hf_dataset[each]['tokens']))]\n",
    "        token_tag_tuple_list.extend(list(zip(ids_list,hf_dataset[each]['tokens'],\n",
    "                                        hf_dataset[each]['ner_tags'])\n",
    "                                       )\n",
    "                                   )\n",
    "        token_tag_tuple_list.append((int(hf_dataset[each]['id']),'[SEP]','[SEP]'))\n",
    "    token_tag_df = pd.DataFrame(token_tag_tuple_list,\n",
    "                                columns=['Sentence_Id','Tokens','Tags']\n",
    "                               )\n",
    "    \n",
    "    print(token_tag_df.head())\n",
    "    token_tag_df['BIO_Tags'] = token_tag_df['Tags'].apply(lambda x: ner_tagging_dict[x] if x != '[SEP]' else '[SEP]')\n",
    "    print(\"spacy processing started\")\n",
    "    spacy_small_tokens_list = []\n",
    "    for i,doc in enumerate(nlp.pipe(token_tag_df['Tokens'],\n",
    "                                    as_tuples=False,  \n",
    "                                    n_process=-1,\n",
    "                                    batch_size=100\n",
    "                       )):\n",
    "        if i%1000 == 0:\n",
    "            print(f\"{i} tokens processed\")\n",
    "        if doc.text == '[SEP]':\n",
    "            spacy_small_tokens_list.append(['[SEP]'])\n",
    "        else:\n",
    "            spacy_small_tokens_list.append([token.text for token in doc])\n",
    "    token_tag_df['Spacy_Small_Tokens'] = spacy_small_tokens_list\n",
    "    print(\"spacy processing over\")\n",
    "    token_tag_df = token_tag_df.explode('Spacy_Small_Tokens')\n",
    "    token_tag_df.reset_index(drop=True,inplace=True)\n",
    "    return token_tag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bef37500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sentence_Id          Tokens Tags\n",
      "0            0  Identification    0\n",
      "1            0              of    0\n",
      "2            0            APC2    0\n",
      "3            0               ,    0\n",
      "4            0               a    0\n",
      "spacy processing started\n",
      "0 tokens processed\n",
      "1000 tokens processed\n",
      "2000 tokens processed\n",
      "3000 tokens processed\n",
      "4000 tokens processed\n",
      "5000 tokens processed\n",
      "6000 tokens processed\n",
      "7000 tokens processed\n",
      "8000 tokens processed\n",
      "9000 tokens processed\n",
      "10000 tokens processed\n",
      "11000 tokens processed\n",
      "12000 tokens processed\n",
      "13000 tokens processed\n",
      "14000 tokens processed\n",
      "15000 tokens processed\n",
      "16000 tokens processed\n",
      "17000 tokens processed\n",
      "18000 tokens processed\n",
      "19000 tokens processed\n",
      "20000 tokens processed\n",
      "21000 tokens processed\n",
      "22000 tokens processed\n",
      "23000 tokens processed\n",
      "24000 tokens processed\n",
      "25000 tokens processed\n",
      "26000 tokens processed\n",
      "27000 tokens processed\n",
      "28000 tokens processed\n",
      "29000 tokens processed\n",
      "30000 tokens processed\n",
      "31000 tokens processed\n",
      "32000 tokens processed\n",
      "33000 tokens processed\n",
      "34000 tokens processed\n",
      "35000 tokens processed\n",
      "36000 tokens processed\n",
      "37000 tokens processed\n",
      "38000 tokens processed\n",
      "39000 tokens processed\n",
      "40000 tokens processed\n",
      "41000 tokens processed\n",
      "42000 tokens processed\n",
      "43000 tokens processed\n",
      "44000 tokens processed\n",
      "45000 tokens processed\n",
      "46000 tokens processed\n",
      "47000 tokens processed\n",
      "48000 tokens processed\n",
      "49000 tokens processed\n",
      "50000 tokens processed\n",
      "51000 tokens processed\n",
      "52000 tokens processed\n",
      "53000 tokens processed\n",
      "54000 tokens processed\n",
      "55000 tokens processed\n",
      "56000 tokens processed\n",
      "57000 tokens processed\n",
      "58000 tokens processed\n",
      "59000 tokens processed\n",
      "60000 tokens processed\n",
      "61000 tokens processed\n",
      "62000 tokens processed\n",
      "63000 tokens processed\n",
      "64000 tokens processed\n",
      "65000 tokens processed\n",
      "66000 tokens processed\n",
      "67000 tokens processed\n",
      "68000 tokens processed\n",
      "69000 tokens processed\n",
      "70000 tokens processed\n",
      "71000 tokens processed\n",
      "72000 tokens processed\n",
      "73000 tokens processed\n",
      "74000 tokens processed\n",
      "75000 tokens processed\n",
      "76000 tokens processed\n",
      "77000 tokens processed\n",
      "78000 tokens processed\n",
      "79000 tokens processed\n",
      "80000 tokens processed\n",
      "81000 tokens processed\n",
      "82000 tokens processed\n",
      "83000 tokens processed\n",
      "84000 tokens processed\n",
      "85000 tokens processed\n",
      "86000 tokens processed\n",
      "87000 tokens processed\n",
      "88000 tokens processed\n",
      "89000 tokens processed\n",
      "90000 tokens processed\n",
      "91000 tokens processed\n",
      "92000 tokens processed\n",
      "93000 tokens processed\n",
      "94000 tokens processed\n",
      "95000 tokens processed\n",
      "96000 tokens processed\n",
      "97000 tokens processed\n",
      "98000 tokens processed\n",
      "99000 tokens processed\n",
      "100000 tokens processed\n",
      "101000 tokens processed\n",
      "102000 tokens processed\n",
      "103000 tokens processed\n",
      "104000 tokens processed\n",
      "105000 tokens processed\n",
      "106000 tokens processed\n",
      "107000 tokens processed\n",
      "108000 tokens processed\n",
      "109000 tokens processed\n",
      "110000 tokens processed\n",
      "111000 tokens processed\n",
      "112000 tokens processed\n",
      "113000 tokens processed\n",
      "114000 tokens processed\n",
      "115000 tokens processed\n",
      "116000 tokens processed\n",
      "117000 tokens processed\n",
      "118000 tokens processed\n",
      "119000 tokens processed\n",
      "120000 tokens processed\n",
      "121000 tokens processed\n",
      "122000 tokens processed\n",
      "123000 tokens processed\n",
      "124000 tokens processed\n",
      "125000 tokens processed\n",
      "126000 tokens processed\n",
      "127000 tokens processed\n",
      "128000 tokens processed\n",
      "129000 tokens processed\n",
      "130000 tokens processed\n",
      "131000 tokens processed\n",
      "132000 tokens processed\n",
      "133000 tokens processed\n",
      "134000 tokens processed\n",
      "135000 tokens processed\n",
      "136000 tokens processed\n",
      "137000 tokens processed\n",
      "138000 tokens processed\n",
      "139000 tokens processed\n",
      "140000 tokens processed\n",
      "141000 tokens processed\n",
      "spacy processing over\n",
      "CPU times: user 53.1 s, sys: 1.85 s, total: 54.9 s\n",
      "Wall time: 59.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data_df = hf_dataset_2_token_tag_df(dataset_builder['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e46ac8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_Id</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Tags</th>\n",
       "      <th>BIO_Tags</th>\n",
       "      <th>Spacy_Small_Tokens</th>\n",
       "      <th>New_Sentence_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Identification</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>Identification</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>of</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>of</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>APC2</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>APC2</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>,</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>a</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>homologue</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>homologue</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>of</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>of</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>the</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>adenomatous</td>\n",
       "      <td>1</td>\n",
       "      <td>B-Disease</td>\n",
       "      <td>adenomatous</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>polyposis</td>\n",
       "      <td>2</td>\n",
       "      <td>I-Disease</td>\n",
       "      <td>polyposis</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>coli</td>\n",
       "      <td>2</td>\n",
       "      <td>I-Disease</td>\n",
       "      <td>coli</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>tumour</td>\n",
       "      <td>2</td>\n",
       "      <td>I-Disease</td>\n",
       "      <td>tumour</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>suppressor</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>suppressor</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>.</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>The</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>The</td>\n",
       "      <td>tr_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>adenomatous</td>\n",
       "      <td>1</td>\n",
       "      <td>B-Disease</td>\n",
       "      <td>adenomatous</td>\n",
       "      <td>tr_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>polyposis</td>\n",
       "      <td>2</td>\n",
       "      <td>I-Disease</td>\n",
       "      <td>polyposis</td>\n",
       "      <td>tr_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>coli</td>\n",
       "      <td>2</td>\n",
       "      <td>I-Disease</td>\n",
       "      <td>coli</td>\n",
       "      <td>tr_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>(</td>\n",
       "      <td>2</td>\n",
       "      <td>I-Disease</td>\n",
       "      <td>(</td>\n",
       "      <td>tr_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>APC</td>\n",
       "      <td>2</td>\n",
       "      <td>I-Disease</td>\n",
       "      <td>APC</td>\n",
       "      <td>tr_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>)</td>\n",
       "      <td>2</td>\n",
       "      <td>I-Disease</td>\n",
       "      <td>)</td>\n",
       "      <td>tr_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>tumour</td>\n",
       "      <td>2</td>\n",
       "      <td>I-Disease</td>\n",
       "      <td>tumour</td>\n",
       "      <td>tr_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>-</td>\n",
       "      <td>tr_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>suppressor</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>suppressor</td>\n",
       "      <td>tr_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence_Id          Tokens   Tags   BIO_Tags Spacy_Small_Tokens  \\\n",
       "0             0  Identification      0          O     Identification   \n",
       "1             0              of      0          O                 of   \n",
       "2             0            APC2      0          O               APC2   \n",
       "3             0               ,      0          O                  ,   \n",
       "4             0               a      0          O                  a   \n",
       "5             0       homologue      0          O          homologue   \n",
       "6             0              of      0          O                 of   \n",
       "7             0             the      0          O                the   \n",
       "8             0     adenomatous      1  B-Disease        adenomatous   \n",
       "9             0       polyposis      2  I-Disease          polyposis   \n",
       "10            0            coli      2  I-Disease               coli   \n",
       "11            0          tumour      2  I-Disease             tumour   \n",
       "12            0      suppressor      0          O         suppressor   \n",
       "13            0               .      0          O                  .   \n",
       "14            0           [SEP]  [SEP]      [SEP]              [SEP]   \n",
       "15            1             The      0          O                The   \n",
       "16            1     adenomatous      1  B-Disease        adenomatous   \n",
       "17            1       polyposis      2  I-Disease          polyposis   \n",
       "18            1            coli      2  I-Disease               coli   \n",
       "19            1               (      2  I-Disease                  (   \n",
       "20            1             APC      2  I-Disease                APC   \n",
       "21            1               )      2  I-Disease                  )   \n",
       "22            1          tumour      2  I-Disease             tumour   \n",
       "23            1               -      0          O                  -   \n",
       "24            1      suppressor      0          O         suppressor   \n",
       "\n",
       "   New_Sentence_Id  \n",
       "0             tr_0  \n",
       "1             tr_0  \n",
       "2             tr_0  \n",
       "3             tr_0  \n",
       "4             tr_0  \n",
       "5             tr_0  \n",
       "6             tr_0  \n",
       "7             tr_0  \n",
       "8             tr_0  \n",
       "9             tr_0  \n",
       "10            tr_0  \n",
       "11            tr_0  \n",
       "12            tr_0  \n",
       "13            tr_0  \n",
       "14            tr_0  \n",
       "15            tr_1  \n",
       "16            tr_1  \n",
       "17            tr_1  \n",
       "18            tr_1  \n",
       "19            tr_1  \n",
       "20            tr_1  \n",
       "21            tr_1  \n",
       "22            tr_1  \n",
       "23            tr_1  \n",
       "24            tr_1  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2351693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_Id</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Tags</th>\n",
       "      <th>BIO_Tags</th>\n",
       "      <th>Spacy_Small_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>adenomatous</td>\n",
       "      <td>1</td>\n",
       "      <td>B-Disease</td>\n",
       "      <td>adenomatous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>polyposis</td>\n",
       "      <td>2</td>\n",
       "      <td>I-Disease</td>\n",
       "      <td>polyposis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>coli</td>\n",
       "      <td>2</td>\n",
       "      <td>I-Disease</td>\n",
       "      <td>coli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>tumour</td>\n",
       "      <td>2</td>\n",
       "      <td>I-Disease</td>\n",
       "      <td>tumour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>adenomatous</td>\n",
       "      <td>1</td>\n",
       "      <td>B-Disease</td>\n",
       "      <td>adenomatous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>polyposis</td>\n",
       "      <td>2</td>\n",
       "      <td>I-Disease</td>\n",
       "      <td>polyposis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>coli</td>\n",
       "      <td>2</td>\n",
       "      <td>I-Disease</td>\n",
       "      <td>coli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>(</td>\n",
       "      <td>2</td>\n",
       "      <td>I-Disease</td>\n",
       "      <td>(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>APC</td>\n",
       "      <td>2</td>\n",
       "      <td>I-Disease</td>\n",
       "      <td>APC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>)</td>\n",
       "      <td>2</td>\n",
       "      <td>I-Disease</td>\n",
       "      <td>)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>tumour</td>\n",
       "      <td>2</td>\n",
       "      <td>I-Disease</td>\n",
       "      <td>tumour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3</td>\n",
       "      <td>colon</td>\n",
       "      <td>1</td>\n",
       "      <td>B-Disease</td>\n",
       "      <td>colon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>3</td>\n",
       "      <td>carcinoma</td>\n",
       "      <td>2</td>\n",
       "      <td>I-Disease</td>\n",
       "      <td>carcinoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>6</td>\n",
       "      <td>colon</td>\n",
       "      <td>1</td>\n",
       "      <td>B-Disease</td>\n",
       "      <td>colon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>6</td>\n",
       "      <td>carcinoma</td>\n",
       "      <td>2</td>\n",
       "      <td>I-Disease</td>\n",
       "      <td>carcinoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>9</td>\n",
       "      <td>cancer</td>\n",
       "      <td>1</td>\n",
       "      <td>B-Disease</td>\n",
       "      <td>cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>10</td>\n",
       "      <td>HNPCC</td>\n",
       "      <td>1</td>\n",
       "      <td>B-Disease</td>\n",
       "      <td>HNPCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>10</td>\n",
       "      <td>colorectal</td>\n",
       "      <td>1</td>\n",
       "      <td>B-Disease</td>\n",
       "      <td>colorectal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>10</td>\n",
       "      <td>cancer</td>\n",
       "      <td>2</td>\n",
       "      <td>I-Disease</td>\n",
       "      <td>cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>11</td>\n",
       "      <td>hereditary</td>\n",
       "      <td>1</td>\n",
       "      <td>B-Disease</td>\n",
       "      <td>hereditary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sentence_Id       Tokens Tags   BIO_Tags Spacy_Small_Tokens\n",
       "8              0  adenomatous    1  B-Disease        adenomatous\n",
       "9              0    polyposis    2  I-Disease          polyposis\n",
       "10             0         coli    2  I-Disease               coli\n",
       "11             0       tumour    2  I-Disease             tumour\n",
       "16             1  adenomatous    1  B-Disease        adenomatous\n",
       "17             1    polyposis    2  I-Disease          polyposis\n",
       "18             1         coli    2  I-Disease               coli\n",
       "19             1            (    2  I-Disease                  (\n",
       "20             1          APC    2  I-Disease                APC\n",
       "21             1            )    2  I-Disease                  )\n",
       "22             1       tumour    2  I-Disease             tumour\n",
       "64             3        colon    1  B-Disease              colon\n",
       "65             3    carcinoma    2  I-Disease          carcinoma\n",
       "179            6        colon    1  B-Disease              colon\n",
       "180            6    carcinoma    2  I-Disease          carcinoma\n",
       "206            9       cancer    1  B-Disease             cancer\n",
       "218           10        HNPCC    1  B-Disease              HNPCC\n",
       "231           10   colorectal    1  B-Disease         colorectal\n",
       "232           10       cancer    2  I-Disease             cancer\n",
       "255           11   hereditary    1  B-Disease         hereditary"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df[train_data_df['BIO_Tags'].str.contains('Disease')].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32093f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sentence_Id    Tokens Tags\n",
      "0            0     BRCA1    0\n",
      "1            0        is    0\n",
      "2            0  secreted    0\n",
      "3            0       and    0\n",
      "4            0  exhibits    0\n",
      "spacy processing started\n",
      "0 tokens processed\n",
      "1000 tokens processed\n",
      "2000 tokens processed\n",
      "3000 tokens processed\n",
      "4000 tokens processed\n",
      "5000 tokens processed\n",
      "6000 tokens processed\n",
      "7000 tokens processed\n",
      "8000 tokens processed\n",
      "9000 tokens processed\n",
      "10000 tokens processed\n",
      "11000 tokens processed\n",
      "12000 tokens processed\n",
      "13000 tokens processed\n",
      "14000 tokens processed\n",
      "15000 tokens processed\n",
      "16000 tokens processed\n",
      "17000 tokens processed\n",
      "18000 tokens processed\n",
      "19000 tokens processed\n",
      "20000 tokens processed\n",
      "21000 tokens processed\n",
      "22000 tokens processed\n",
      "23000 tokens processed\n",
      "24000 tokens processed\n",
      "spacy processing over\n",
      "   Sentence_Id      Tokens Tags\n",
      "0            0  Clustering    0\n",
      "1            0          of    0\n",
      "2            0    missense    0\n",
      "3            0   mutations    0\n",
      "4            0          in    0\n",
      "spacy processing started\n",
      "0 tokens processed\n",
      "1000 tokens processed\n",
      "2000 tokens processed\n",
      "3000 tokens processed\n",
      "4000 tokens processed\n",
      "5000 tokens processed\n",
      "6000 tokens processed\n",
      "7000 tokens processed\n",
      "8000 tokens processed\n",
      "9000 tokens processed\n",
      "10000 tokens processed\n",
      "11000 tokens processed\n",
      "12000 tokens processed\n",
      "13000 tokens processed\n",
      "14000 tokens processed\n",
      "15000 tokens processed\n",
      "16000 tokens processed\n",
      "17000 tokens processed\n",
      "18000 tokens processed\n",
      "19000 tokens processed\n",
      "20000 tokens processed\n",
      "21000 tokens processed\n",
      "22000 tokens processed\n",
      "23000 tokens processed\n",
      "24000 tokens processed\n",
      "25000 tokens processed\n",
      "spacy processing over\n",
      "CPU times: user 18.8 s, sys: 2.5 s, total: 21.3 s\n",
      "Wall time: 21.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "val_data_df = hf_dataset_2_token_tag_df(dataset_builder['validation'])\n",
    "test_data_df = hf_dataset_2_token_tag_df(dataset_builder['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "eb2b8f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_Id</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Tags</th>\n",
       "      <th>BIO_Tags</th>\n",
       "      <th>Spacy_Small_Tokens</th>\n",
       "      <th>New_Sentence_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25476</th>\n",
       "      <td>939</td>\n",
       "      <td>cancers</td>\n",
       "      <td>2</td>\n",
       "      <td>I-Disease</td>\n",
       "      <td>cancers</td>\n",
       "      <td>tes_939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25477</th>\n",
       "      <td>939</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>.</td>\n",
       "      <td>tes_939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25478</th>\n",
       "      <td>939</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>.</td>\n",
       "      <td>tes_939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25479</th>\n",
       "      <td>939</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>tes_939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25480</th>\n",
       "      <td>940</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>tes_940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentence_Id   Tokens   Tags   BIO_Tags Spacy_Small_Tokens  \\\n",
       "25476          939  cancers      2  I-Disease            cancers   \n",
       "25477          939        .      0          O                  .   \n",
       "25478          939        .      0          O                  .   \n",
       "25479          939    [SEP]  [SEP]      [SEP]              [SEP]   \n",
       "25480          940    [SEP]  [SEP]      [SEP]              [SEP]   \n",
       "\n",
       "      New_Sentence_Id  \n",
       "25476         tes_939  \n",
       "25477         tes_939  \n",
       "25478         tes_939  \n",
       "25479         tes_939  \n",
       "25480         tes_940  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "72c91f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_token_level_annotated_data = pd.concat([train_data_df[:-1], val_data_df[:-1], test_data_df[:-1]], # ignoring empty sentences \n",
    "                                             axis=0\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "74b23ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191977, 6)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_token_level_annotated_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3ae427fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_Id</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Tags</th>\n",
       "      <th>BIO_Tags</th>\n",
       "      <th>Spacy_Small_Tokens</th>\n",
       "      <th>New_Sentence_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25475</th>\n",
       "      <td>939</td>\n",
       "      <td>breast</td>\n",
       "      <td>2</td>\n",
       "      <td>I-Disease</td>\n",
       "      <td>breast</td>\n",
       "      <td>tes_939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25476</th>\n",
       "      <td>939</td>\n",
       "      <td>cancers</td>\n",
       "      <td>2</td>\n",
       "      <td>I-Disease</td>\n",
       "      <td>cancers</td>\n",
       "      <td>tes_939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25477</th>\n",
       "      <td>939</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>.</td>\n",
       "      <td>tes_939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25478</th>\n",
       "      <td>939</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>.</td>\n",
       "      <td>tes_939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25479</th>\n",
       "      <td>939</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>tes_939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentence_Id   Tokens   Tags   BIO_Tags Spacy_Small_Tokens  \\\n",
       "25475          939   breast      2  I-Disease             breast   \n",
       "25476          939  cancers      2  I-Disease            cancers   \n",
       "25477          939        .      0          O                  .   \n",
       "25478          939        .      0          O                  .   \n",
       "25479          939    [SEP]  [SEP]      [SEP]              [SEP]   \n",
       "\n",
       "      New_Sentence_Id  \n",
       "25475         tes_939  \n",
       "25476         tes_939  \n",
       "25477         tes_939  \n",
       "25478         tes_939  \n",
       "25479         tes_939  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_token_level_annotated_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5869fe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_token_level_annotated_data = final_token_level_annotated_data[['New_Sentence_Id','Spacy_Small_Tokens','BIO_Tags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eea59041",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_token_level_annotated_data.rename(columns={'BIO_Tags':'Human_Annotated_Tag_BIO'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa18594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ../data/diease_ner/conll_spacy_tokenized_ner_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d270c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACY_TOKENIZED_DIR = '../data/diease_ner/conll_spacy_tokenized_ner_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "577cf355",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_token_level_annotated_data.to_csv(f'{SPACY_TOKENIZED_DIR}/token_level_annotated_data.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea03d954",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df['New_Sentence_Id'] = \"tr_\" + train_data_df['Sentence_Id'].astype(str) \n",
    "val_data_df['New_Sentence_Id'] = \"val_\" + val_data_df['Sentence_Id'].astype(str) \n",
    "test_data_df['New_Sentence_Id'] = \"tes_\" + test_data_df['Sentence_Id'].astype(str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9576bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_Id</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Tags</th>\n",
       "      <th>BIO_Tags</th>\n",
       "      <th>Spacy_Small_Tokens</th>\n",
       "      <th>New_Sentence_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Identification</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>Identification</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>of</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>of</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>APC2</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>APC2</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>,</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>a</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentence_Id          Tokens Tags BIO_Tags Spacy_Small_Tokens  \\\n",
       "0            0  Identification    0        O     Identification   \n",
       "1            0              of    0        O                 of   \n",
       "2            0            APC2    0        O               APC2   \n",
       "3            0               ,    0        O                  ,   \n",
       "4            0               a    0        O                  a   \n",
       "\n",
       "  New_Sentence_Id  \n",
       "0            tr_0  \n",
       "1            tr_0  \n",
       "2            tr_0  \n",
       "3            tr_0  \n",
       "4            tr_0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0507c7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df.to_csv(f'{SPACY_TOKENIZED_DIR}/train_data.csv',index=None)\n",
    "val_data_df.to_csv(f'{SPACY_TOKENIZED_DIR}/val_data.csv',index=None)\n",
    "test_data_df.to_csv(f'{SPACY_TOKENIZED_DIR}/test_data.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3013a8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_Id</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Tags</th>\n",
       "      <th>BIO_Tags</th>\n",
       "      <th>Spacy_Small_Tokens</th>\n",
       "      <th>New_Sentence_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Identification</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>Identification</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>of</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>of</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>APC2</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>APC2</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>,</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>a</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>homologue</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>homologue</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>of</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>of</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>the</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>adenomatous</td>\n",
       "      <td>1</td>\n",
       "      <td>B-Disease</td>\n",
       "      <td>adenomatous</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>polyposis</td>\n",
       "      <td>2</td>\n",
       "      <td>I-Disease</td>\n",
       "      <td>polyposis</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>coli</td>\n",
       "      <td>2</td>\n",
       "      <td>I-Disease</td>\n",
       "      <td>coli</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>tumour</td>\n",
       "      <td>2</td>\n",
       "      <td>I-Disease</td>\n",
       "      <td>tumour</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>suppressor</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>suppressor</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>.</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>tr_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence_Id          Tokens   Tags   BIO_Tags Spacy_Small_Tokens  \\\n",
       "0             0  Identification      0          O     Identification   \n",
       "1             0              of      0          O                 of   \n",
       "2             0            APC2      0          O               APC2   \n",
       "3             0               ,      0          O                  ,   \n",
       "4             0               a      0          O                  a   \n",
       "5             0       homologue      0          O          homologue   \n",
       "6             0              of      0          O                 of   \n",
       "7             0             the      0          O                the   \n",
       "8             0     adenomatous      1  B-Disease        adenomatous   \n",
       "9             0       polyposis      2  I-Disease          polyposis   \n",
       "10            0            coli      2  I-Disease               coli   \n",
       "11            0          tumour      2  I-Disease             tumour   \n",
       "12            0      suppressor      0          O         suppressor   \n",
       "13            0               .      0          O                  .   \n",
       "14            0           [SEP]  [SEP]      [SEP]              [SEP]   \n",
       "\n",
       "   New_Sentence_Id  \n",
       "0             tr_0  \n",
       "1             tr_0  \n",
       "2             tr_0  \n",
       "3             tr_0  \n",
       "4             tr_0  \n",
       "5             tr_0  \n",
       "6             tr_0  \n",
       "7             tr_0  \n",
       "8             tr_0  \n",
       "9             tr_0  \n",
       "10            tr_0  \n",
       "11            tr_0  \n",
       "12            tr_0  \n",
       "13            tr_0  \n",
       "14            tr_0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df[train_data_df['New_Sentence_Id']=='tr_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266e0b09",
   "metadata": {},
   "source": [
    "### 2. Prepare Model Training Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6366a5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONLL_TRAINING_DIR = '../data/diease_ner/conll_compatible_ner_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17f3b63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $CONLL_TRAINING_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a77dcf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_token_df_2_conll_format(token_tag_df,\n",
    "                                    token_column_name,\n",
    "                                    tag_column_name\n",
    "                                   ):\n",
    "    token_string = ''\n",
    "    for each in range(len(token_tag_df)):\n",
    "        current_token_string = str(token_tag_df.loc[each,token_column_name])\n",
    "        current_tag_string = str(token_tag_df.loc[each,tag_column_name])\n",
    "        \n",
    "        if current_token_string !='[SEP]':\n",
    "            current_line = current_token_string + \"\\t\" + current_tag_string + \"\\n\"\n",
    "        else:\n",
    "            current_line = \"\\n\"\n",
    "        token_string = token_string + current_line\n",
    "    return token_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80508c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.43 s, sys: 37.8 ms, total: 2.47 s\n",
      "Wall time: 2.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data_string = convert_token_df_2_conll_format(train_data_df,\n",
    "                                             'Spacy_Small_Tokens',\n",
    "                                             'BIO_Tags'\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6db15811",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{CONLL_TRAINING_DIR}/train_data.conll','w',encoding='utf-8') as f:\n",
    "    f.write(train_data_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2f7dd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 878 ms, sys: 17.9 ms, total: 896 ms\n",
      "Wall time: 897 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "val_data_string = convert_token_df_2_conll_format(val_data_df,\n",
    "                                             'Spacy_Small_Tokens',\n",
    "                                             'BIO_Tags'\n",
    "                                            )\n",
    "\n",
    "with open(f'{CONLL_TRAINING_DIR}/val_data.conll','w',encoding='utf-8') as f:\n",
    "    f.write(val_data_string)\n",
    "    \n",
    "    \n",
    "test_data_string = convert_token_df_2_conll_format(test_data_df,\n",
    "                                             'Spacy_Small_Tokens',\n",
    "                                             'BIO_Tags'\n",
    "                                            )\n",
    "\n",
    "with open(f'{CONLL_TRAINING_DIR}/test_data.conll','w',encoding='utf-8') as f:\n",
    "    f.write(test_data_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "844a5443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering\tO\r\n",
      "of\tO\r\n",
      "missense\tO\r\n",
      "mutations\tO\r\n",
      "in\tO\r\n",
      "the\tO\r\n",
      "ataxia\tB-Disease\r\n",
      "-\tI-Disease\r\n",
      "telangiectasia\tI-Disease\r\n",
      "gene\tO\r\n",
      "in\tO\r\n",
      "a\tO\r\n",
      "sporadic\tB-Disease\r\n",
      "T\tI-Disease\r\n",
      "-\tI-Disease\r\n",
      "cell\tI-Disease\r\n",
      "leukaemia\tI-Disease\r\n",
      ".\tO\r\n",
      "\r\n",
      "Ataxia\tB-Disease\r\n",
      "-\tI-Disease\r\n",
      "telangiectasia\tI-Disease\r\n",
      "(\tO\r\n",
      "A\tB-Disease\r\n",
      "-\tI-Disease\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 25 $CONLL_TRAINING_DIR/test_data.conll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295305cb",
   "metadata": {},
   "source": [
    "### 3.Prepare `Unlabeled` Sentences for building a Spacy Rules Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "01a56f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split_a_sequence(sequence, sep):\n",
    "    chunk = []\n",
    "    for val in sequence:\n",
    "        if val[1] == sep:\n",
    "            yield chunk\n",
    "            chunk = []\n",
    "        else:\n",
    "            chunk.append(val)\n",
    "    yield chunk\n",
    "    \n",
    "\n",
    "def token_tags_2_sentences(tokens_tags_df):\n",
    "    new_df = pd.DataFrame(tokens_tags_df.groupby('New_Sentence_Id')['Spacy_Small_Tokens'].apply(list))\n",
    "    new_df = new_df.reset_index()\n",
    "    new_df['Sentence'] = new_df['Spacy_Small_Tokens'].apply(lambda x: \" \".join(x[:-1]))\n",
    "    new_df = new_df[['New_Sentence_Id', 'Sentence']]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "00f40e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNLABELED_SENTENCE_DIR = '../data/diease_ner/unlabeled_sentences/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2cb685d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $UNLABELED_SENTENCE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8f29e5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141590, 6)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6601322e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 167 ms, sys: 7.99 ms, total: 175 ms\n",
      "Wall time: 174 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_sentence_df = token_tags_2_sentences(train_data_df)\n",
    "val_sentence_df = token_tags_2_sentences(val_data_df)\n",
    "test_sentence_df = token_tags_2_sentences(test_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9b4727e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>New_Sentence_Id</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>Identification of APC2 , a homologue of the ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tr_1</td>\n",
       "      <td>The adenomatous polyposis coli ( APC ) tumour ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tr_10</td>\n",
       "      <td>A common MSH2 mutation in English and North Am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tr_100</td>\n",
       "      <td>The positive control for DMT1 up - regulation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tr_1000</td>\n",
       "      <td>The history further indicated intrauterine gro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  New_Sentence_Id                                           Sentence\n",
       "0            tr_0  Identification of APC2 , a homologue of the ad...\n",
       "1            tr_1  The adenomatous polyposis coli ( APC ) tumour ...\n",
       "2           tr_10  A common MSH2 mutation in English and North Am...\n",
       "3          tr_100  The positive control for DMT1 up - regulation ...\n",
       "4         tr_1000  The history further indicated intrauterine gro..."
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5174f786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Identification of APC2 , a homologue of the adenomatous polyposis coli tumour suppressor .'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentence_df.loc[0,'Sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a435afad",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_sentence_level_data = pd.concat([train_sentence_df, \n",
    "                                          val_sentence_df,\n",
    "                                          test_sentence_df\n",
    "                                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1d9079b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_sentence_level_data.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "699807f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>New_Sentence_Id</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>Identification of APC2 , a homologue of the ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tr_1</td>\n",
       "      <td>The adenomatous polyposis coli ( APC ) tumour ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tr_10</td>\n",
       "      <td>A common MSH2 mutation in English and North Am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tr_100</td>\n",
       "      <td>The positive control for DMT1 up - regulation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tr_1000</td>\n",
       "      <td>The history further indicated intrauterine gro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  New_Sentence_Id                                           Sentence\n",
       "0            tr_0  Identification of APC2 , a homologue of the ad...\n",
       "1            tr_1  The adenomatous polyposis coli ( APC ) tumour ...\n",
       "2           tr_10  A common MSH2 mutation in English and North Am...\n",
       "3          tr_100  The positive control for DMT1 up - regulation ...\n",
       "4         tr_1000  The history further indicated intrauterine gro..."
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_sentence_level_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "70c5a099",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_sentence_level_data.to_csv(f'{UNLABELED_SENTENCE_DIR}/complete_data_for_rules_tagging.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f52771",
   "metadata": {},
   "source": [
    "Training % of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "391adb47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7444505343929844"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentence_df)/ (len(train_sentence_df) + \n",
    "                            len(val_sentence_df) +\n",
    "                            len(test_sentence_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b1dedc",
   "metadata": {},
   "source": [
    "Validation % of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9961949f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12661003014524527"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_sentence_df)/ (len(train_sentence_df) + \n",
    "                            len(val_sentence_df) +\n",
    "                            len(test_sentence_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b55b98",
   "metadata": {},
   "source": [
    "Test % of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5b45900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12893943546177034"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_sentence_df)/ (len(train_sentence_df) + \n",
    "                            len(val_sentence_df) +\n",
    "                            len(test_sentence_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b4001e",
   "metadata": {},
   "source": [
    "### Key Disease Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7cf5d67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_words = list(train_data_df[train_data_df['BIO_Tags'].str.contains('I-Disease')]['Tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a0c9e9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.7 s, sys: 88.7 ms, total: 17.8 s\n",
      "Wall time: 17.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "disease_words = [token.lemma_ for word in disease_words for token in nlp(word) if token.tag_.startswith('N')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f3276194",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_disease_words = list(set(disease_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c8f0229a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "503"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_disease_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "54cc89c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CETP',\n",
       " 'deficienty',\n",
       " 'male',\n",
       " 'retina',\n",
       " 'secretion',\n",
       " 'CYP27',\n",
       " 'scalp',\n",
       " 'peripheral',\n",
       " 'PKU',\n",
       " 'willi',\n",
       " 'keratoderma',\n",
       " 'homeostasis',\n",
       " 'cyst',\n",
       " 'EMD',\n",
       " 'syndrome',\n",
       " 'demyelination',\n",
       " 'hemolytic',\n",
       " 'sarcoma',\n",
       " 'IIA',\n",
       " 'EC']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_disease_words[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8cf9e2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"cancer\" in unique_disease_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2712746",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"cancer\" in unique_disease_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
