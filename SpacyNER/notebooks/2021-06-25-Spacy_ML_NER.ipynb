{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b7c7499",
   "metadata": {},
   "source": [
    "# How to train a Spacy NER Model_WIP\n",
    "> In this blog post, I cover the process of creating trained ML NER model from Unlabeled data\n",
    "- toc: true\n",
    "- branch: master\n",
    "- author: Senthil Kumar\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [spacy/NER]\n",
    "- image: images/spacy/spacy_ML_model_training_on_unlabeld_data.png\n",
    "- hide: false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e42db8",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe63cfa5",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6510dc",
   "metadata": {},
   "source": [
    "### TL;DR Summary of the Blog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92f2644",
   "metadata": {},
   "source": [
    "**How do we create ML NER Model from no labeled data?**: \n",
    "\n",
    "- Prepare **rules-bootstrapped training data** from unlabeled corpus\n",
    "   - If it is possible/easy  to annotate directly, one can do that. \n",
    "   - However, if rules taggging is possible \n",
    "       - In the **Disease NER dataset** example here\n",
    "       - there is an opportunity to use a huge list of words to tag via rules first\n",
    "       - then labeling becomes easier than labeling from scratch\n",
    "- Rules-boostrapped data is then **reviewed/edited by human annotators** \n",
    "- **Stratify Split** the human-reviewed data into train-dev-test at sentences level\n",
    "- Optimize and **Train** one or more Spacy ML NER Models \n",
    "- **Compare** and **Evaluate** the accuracy of the models \n",
    "\n",
    "![](spacy_model_ner/spacy_ML_model_training_on_unlabeld_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0a39ca",
   "metadata": {},
   "source": [
    "**Now, we can list the above steps with a DISEASE NER example ...**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787d4bce",
   "metadata": {},
   "source": [
    "- We have a `ncbi_disease` dataset of `7295` sentences speaking of various entities of which `disease` entity is of focus for us. \n",
    "> E.g.: \"Identification of APC2 , a homologue of the adenomatous polyposis coli tumour suppressor .\" <br>\n",
    "> `adenomatous polyposis coli tumour` is a `DISEASE` entity\n",
    "\n",
    "- Source of this dataset: [link](https://huggingface.co/datasets/lewtun/autoevaluate__ncbi_disease)\n",
    "\n",
    "- For the sake of the argument of this blog, we assume this dataset does not have labels. \n",
    "- In most real world datasets, we are most not likely to encounter labeled data\n",
    "\n",
    "<br>\n",
    "\n",
    "- Hence the below pipeline helps in building an ML model\n",
    "> 1. Unlabeled Sentences speaking of various diseases <br>\n",
    "> 2. Tag `DISEASE` NER via Rules using a huge list of [disease words](https://raw.githubusercontent.com/Shivanshu-Gupta/web-scrapers/master/medical_ner/medicinenet-diseases.json) <br>\n",
    "> 3. Review/Edit the Rules-bootstrapped NER (tagging NER from scratch is a lot tougher)\n",
    "> 4. Split the Data into train-dev-test<br>\n",
    "> 5. Train an ML model on train and dev datasets and evaluate on unseen test dataset\n",
    "> 6. Evaluate & Compare the Rules Model (baseline) and Spacy ML NER models (built from spacy-small and roberta base)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d125352e",
   "metadata": {},
   "source": [
    "## 2. Prepare Rules-bootstrapped Data from unlabeled data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd67f33",
   "metadata": {},
   "source": [
    "### 2A. Loading the disease words from an external file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03b509ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hemophilia',\n",
       " 'Hemophilia A',\n",
       " 'Hepatitis A',\n",
       " 'Abdominal Aortic Aneurysm',\n",
       " 'AAA',\n",
       " 'Alpha 1 Antitrypsin Deficiency',\n",
       " 'AAT',\n",
       " 'AATD',\n",
       " 'Scar Tissue',\n",
       " 'Abdominal Adhesions']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collapse-show\n",
    "import json\n",
    "import re\n",
    "\n",
    "with open('./spacy_model_ner/diseases_ner.json','r') as f:\n",
    "    diseases_json = json.load(f)\n",
    "    \n",
    "list_of_diseases = [each['disease'] for each in diseases_json if not re.search('[,]|test',each['disease'],re.I)]\n",
    "\n",
    "list_of_diseases.extend(['tumor','tumour']) #adding some custom word\n",
    "\n",
    "list_of_diseases[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad61f57",
   "metadata": {},
   "source": [
    "### 2B. Convert Disease Words into Spacy Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32b6a8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'DISEASE', 'pattern': [{'LOWER': 'hemophilia'}]},\n",
       " {'label': 'DISEASE', 'pattern': [{'LOWER': 'hemophilia'}, {'LOWER': 'a'}]},\n",
       " {'label': 'DISEASE', 'pattern': [{'LOWER': 'hepatitis'}, {'LOWER': 'a'}]},\n",
       " {'label': 'DISEASE',\n",
       "  'pattern': [{'LOWER': 'abdominal'},\n",
       "   {'LOWER': 'aortic'},\n",
       "   {'LOWER': 'aneurysm'}]},\n",
       " {'label': 'DISEASE', 'pattern': [{'LOWER': 'aaa'}]}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collapse-show\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm',disable=['ner']) #ner component is not needed; \n",
    "\n",
    "def list_of_words_2_spacy_patterns(list_of_words,\n",
    "                                   nlp_model,\n",
    "                                   label_name\n",
    "                                  ):\n",
    "    spacy_patterns = []\n",
    "    for each_word in list_of_words:\n",
    "        sub_pattern_list = [] # [{\"ORTH\": user_text_entity_df.loc[each_pattern_index,'TEXT']}]\n",
    "        for token in  nlp_model(each_word.lower()):\n",
    "            if re.search('^\\W{1,}$',token.text):\n",
    "                sub_pattern_list.append({\"ORTH\": token.text,\"OP\":\"*\"})\n",
    "            else:\n",
    "                sub_pattern_list.append({\"LOWER\":token.text})\n",
    "        temp_dict = {\"label\": label_name,\n",
    "                     \"pattern\": sub_pattern_list}\n",
    "        spacy_patterns.append(temp_dict)\n",
    "    return spacy_patterns\n",
    "\n",
    "disease_spacy_rules_patterns = list_of_words_2_spacy_patterns(list_of_diseases,\n",
    "                               nlp,\n",
    "                               \"DISEASE\"\n",
    "                              )\n",
    "\n",
    "disease_spacy_rules_patterns[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194c1c11",
   "metadata": {},
   "source": [
    "### 2C. Create `Disease NER` out of spacy patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c111dbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pipeline components are:\n",
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'disease_rules']\n",
      "NER entities tracked are:\n",
      "['DISEASE']\n"
     ]
    }
   ],
   "source": [
    "# collapse-show\n",
    "\n",
    "def load_rules_nlp_model_from_spacy_patterns(spacy_patterns):\n",
    "    rules_nlp = spacy.load('en_core_web_sm',disable=['ner'])\n",
    "    rules_config = {\n",
    "        \"validate\": True,\n",
    "        \"overwrite_ents\": True,\n",
    "    }\n",
    "\n",
    "    disease_rules = rules_nlp.add_pipe(\"entity_ruler\", # invoke entity_ruler pipe \n",
    "                                       \"disease_rules\", # give a name to the pipe\n",
    "                                       config=rules_config)\n",
    "    disease_rules.add_patterns(spacy_patterns)\n",
    "    return rules_nlp\n",
    "\n",
    "disease_ner_rules_nlp = load_rules_nlp_model_from_spacy_patterns(disease_spacy_rules_patterns)\n",
    "\n",
    "print(\"The pipeline components are:\")\n",
    "print(disease_ner_rules_nlp.pipe_names)\n",
    "print(\"NER entities tracked are:\")\n",
    "print(disease_ner_rules_nlp.pipe_labels['disease_rules'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fef620",
   "metadata": {},
   "source": [
    "- Want to know more about creating rules NER? <br> \n",
    "Refer the below blog article <br>[learn_by_blogging/How_to_Leverage_Spacy_Rules_NER](https://senthilkumarm1901.github.io/learn_by_blogging/spacy/ner/2021/05/09/Spacy_Rules_NER.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076795ad",
   "metadata": {},
   "source": [
    "### 2D. Infer Spacy Rules NER as token-level results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e723e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse-hide\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "## The token-level results from the above model on 7.2K sentences looks like below\n",
    "token_level_rules_output_example = pd.read_csv('spacy_model_ner/token_level_tags_on_one_unlabeled_sentence.csv',index_col=False)\n",
    "token_level_rules_output_example = token_level_rules_output_example[['New_Sentence_Id','Token','Rules_Tag_BIO']]\n",
    "token_level_rules_output_example.columns = ['Ramdom_Sentence_Id','Token','Rules_Tag_BIO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1b2ebd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ramdom_Sentence_Id</th>\n",
       "      <th>Token</th>\n",
       "      <th>Rules_Tag_BIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>Identification</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>APC2</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>a</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>homologue</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>adenomatous</td>\n",
       "      <td>B-DISEASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>polyposis</td>\n",
       "      <td>I-DISEASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>coli</td>\n",
       "      <td>I-DISEASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>tumour</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>suppressor</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>[SEP]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ramdom_Sentence_Id           Token Rules_Tag_BIO\n",
       "0                tr_0  Identification             O\n",
       "1                tr_0              of             O\n",
       "2                tr_0            APC2             O\n",
       "3                tr_0               ,             O\n",
       "4                tr_0               a             O\n",
       "5                tr_0       homologue             O\n",
       "6                tr_0              of             O\n",
       "7                tr_0             the             O\n",
       "8                tr_0     adenomatous     B-DISEASE\n",
       "9                tr_0       polyposis     I-DISEASE\n",
       "10               tr_0            coli     I-DISEASE\n",
       "11               tr_0          tumour             O\n",
       "12               tr_0      suppressor             O\n",
       "13               tr_0               .             O\n",
       "14               tr_0           [SEP]         [SEP]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collapse-show\n",
    "token_level_rules_output_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad54e085",
   "metadata": {},
   "source": [
    "- Ofcourse, there are mistakes in this `rules_ner output` like in row #11 where `tumour` is not tagged `I-DISEASE`\n",
    "- We rectify the mistakes of rules by human annotion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cafa55",
   "metadata": {},
   "source": [
    "## 3. Human Review of the Rules Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9cfb35",
   "metadata": {},
   "source": [
    "### 3A. Edit token-level results in csv by human annotation/review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3898ec09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>New_Sentence_Id</th>\n",
       "      <th>Token</th>\n",
       "      <th>Rules_Tag_BIO</th>\n",
       "      <th>Human_Annotated_Tag_BIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>Identification</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>APC2</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>a</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>homologue</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>adenomatous</td>\n",
       "      <td>B-DISEASE</td>\n",
       "      <td>B-DISEASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>polyposis</td>\n",
       "      <td>I-DISEASE</td>\n",
       "      <td>I-DISEASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>coli</td>\n",
       "      <td>I-DISEASE</td>\n",
       "      <td>I-DISEASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>tumour</td>\n",
       "      <td>O</td>\n",
       "      <td>I-DISEASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>suppressor</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tr_0</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>[SEP]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   New_Sentence_Id           Token Rules_Tag_BIO Human_Annotated_Tag_BIO\n",
       "0             tr_0  Identification             O                       O\n",
       "1             tr_0              of             O                       O\n",
       "2             tr_0              of             O                       O\n",
       "3             tr_0              of             O                       O\n",
       "4             tr_0              of             O                       O\n",
       "5             tr_0            APC2             O                       O\n",
       "6             tr_0               ,             O                       O\n",
       "7             tr_0               a             O                       O\n",
       "8             tr_0       homologue             O                       O\n",
       "9             tr_0             the             O                       O\n",
       "10            tr_0     adenomatous     B-DISEASE               B-DISEASE\n",
       "11            tr_0       polyposis     I-DISEASE               I-DISEASE\n",
       "12            tr_0            coli     I-DISEASE               I-DISEASE\n",
       "13            tr_0          tumour             O               I-DISEASE\n",
       "14            tr_0      suppressor             O                       O\n",
       "15            tr_0               .             O                       O\n",
       "16            tr_0           [SEP]         [SEP]                   [SEP]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collapse-show\n",
    "## The token-level results from the above model on 7.2K sentences looks like below\n",
    "token_level_rules_plus_human_output_example = pd.read_csv('spacy_model_ner/token_level_tags_on_one_unlabeled_sentence_2.csv',index_col=False)\n",
    "token_level_rules_plus_human_output_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e15edb",
   "metadata": {},
   "source": [
    "## 4. Stratify Split the Data based on human annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "106f7a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Sentences: 7295\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_level_tags</th>\n",
       "      <th>Count</th>\n",
       "      <th>%_contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O</td>\n",
       "      <td>3337</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-DISEASE|I-DISEASE|O</td>\n",
       "      <td>2698</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-DISEASE|O</td>\n",
       "      <td>1260</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sentence_level_tags  Count  %_contribution\n",
       "0                      O   3337            46.0\n",
       "1  B-DISEASE|I-DISEASE|O   2698            37.0\n",
       "2            B-DISEASE|O   1260            17.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collapse-show\n",
    "sentence_level_count_df = pd.read_csv('spacy_model_ner/split_of_classes_sentence_level.csv',index_col=False)\n",
    "print(f\"Total number of Sentences: {sum(sentence_level_count_df['Count'])}\")\n",
    "sentence_level_count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd3c939",
   "metadata": {},
   "source": [
    "From the above table, we can infer that <br>\n",
    "- there are more multi-token diseases than single-token diseases\n",
    "- there are 3.3K sentences with only `O` as the token\n",
    "<br>\n",
    "<br>\n",
    "We have to ensure all three splits - train, dev and test - have the same percentage of `O`, `B-DISEASE|I-DISEASE|O` and `B-DISEASE|O`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9439201d",
   "metadata": {},
   "source": [
    "After spliting into train-dev-test in a 80-10-10 split ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df68db69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Train Sentences: 5836\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_level_tags</th>\n",
       "      <th>Count</th>\n",
       "      <th>%_contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O</td>\n",
       "      <td>2670</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-DISEASE|I-DISEASE|O</td>\n",
       "      <td>2158</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-DISEASE|O</td>\n",
       "      <td>1008</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sentence_level_tags  Count  %_contribution\n",
       "0                      O   2670            46.0\n",
       "1  B-DISEASE|I-DISEASE|O   2158            37.0\n",
       "2            B-DISEASE|O   1008            17.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collapse-show\n",
    "train_count_df = pd.read_csv('spacy_model_ner/split_of_classes_sentence_level_train.csv',index_col=False)\n",
    "print(f\"Total number of Train Sentences: {sum(train_count_df['Count'])}\")\n",
    "train_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c8c28fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Train Sentences: 729\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_level_tags</th>\n",
       "      <th>Count</th>\n",
       "      <th>%_contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O</td>\n",
       "      <td>333</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-DISEASE|I-DISEASE|O</td>\n",
       "      <td>270</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-DISEASE|O</td>\n",
       "      <td>126</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sentence_level_tags  Count  %_contribution\n",
       "0                      O    333            46.0\n",
       "1  B-DISEASE|I-DISEASE|O    270            37.0\n",
       "2            B-DISEASE|O    126            17.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collapse-show\n",
    "dev_count_df = pd.read_csv('spacy_model_ner/split_of_classes_sentence_level_dev.csv',index_col=False)\n",
    "print(f\"Total number of Train Sentences: {sum(dev_count_df['Count'])}\")\n",
    "dev_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8b16cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Train Sentences: 730\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_level_tags</th>\n",
       "      <th>Count</th>\n",
       "      <th>%_contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O</td>\n",
       "      <td>334</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-DISEASE|I-DISEASE|O</td>\n",
       "      <td>270</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-DISEASE|O</td>\n",
       "      <td>126</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sentence_level_tags  Count  %_contribution\n",
       "0                      O    334            46.0\n",
       "1  B-DISEASE|I-DISEASE|O    270            37.0\n",
       "2            B-DISEASE|O    126            17.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collapse-show\n",
    "test_count_df = pd.read_csv('spacy_model_ner/split_of_classes_sentence_level_test.csv',index_col=False)\n",
    "print(f\"Total number of Train Sentences: {sum(test_count_df['Count'])}\")\n",
    "test_count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e83ebea",
   "metadata": {},
   "source": [
    "## 5. Train ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc59161",
   "metadata": {},
   "source": [
    "### 5A. Convert token-level Results 2 Spacy Model-acceptable Conll Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6155926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse-show\n",
    "\n",
    "def convert_token_df_2_conll_string(token_tag_df,\n",
    "                                    token_column_name,\n",
    "                                    tag_column_name\n",
    "                                   ):\n",
    "    token_string = ''\n",
    "    for each in range(len(token_tag_df)):\n",
    "        if each %1000 == 0:\n",
    "            print(f\"{each} tokens processed\")\n",
    "        current_token_string = str(token_tag_df.loc[each,token_column_name])\n",
    "        current_tag_string = str(token_tag_df.loc[each,tag_column_name])\n",
    "        \n",
    "        if current_token_string !='[SEP]':\n",
    "            current_line = current_token_string + \"\\t\" + current_tag_string + \"\\n\"\n",
    "        else:\n",
    "            current_line = \"\\n\"\n",
    "        token_string = token_string + current_line\n",
    "    return token_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20ad5d73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "investigate\tO\r\n",
      "the\tO\r\n",
      "rate\tO\r\n",
      "of\tO\r\n",
      "BRCA2\tO\r\n",
      "mutation\tO\r\n",
      "in\tO\r\n",
      "sporadic\tB-DISEASE\r\n",
      "breast\tI-DISEASE\r\n",
      "cancers\tI-DISEASE\r\n",
      "and\tO\r\n",
      "in\tO\r\n",
      "a\tO\r\n",
      "set\tO\r\n",
      "of\tO\r\n",
      "cell\tO\r\n",
      "lines\tO\r\n",
      "that\tO\r\n",
      "represent\tO\r\n",
      "twelve\tO\r\n",
      "other\tO\r\n",
      "tumour\tB-DISEASE\r\n",
      "types\tO\r\n",
      ".\tO\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 25 ../data/diease_ner/train_dev_test_split_conll_data/test_data.conll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed24380",
   "metadata": {},
   "source": [
    "### 5B. Train a Spacy Small ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c50750e",
   "metadata": {},
   "source": [
    "**CLI command for Spacy Model Training**:\n",
    "\n",
    "```\n",
    "!python3 -m spacy train $CONFIG_DIR/original_spacy_small_ner_config.cfg \\\n",
    "--output $SPACY_SMALL_MODEL_DIR_GPU \\\n",
    "--paths.train $SPACY_DATA_DIR/train_data.spacy \\\n",
    "--paths.dev $SPACY_DATA_DIR/dev_data.spacy \\\n",
    "--verbose \\\n",
    "-g 0\n",
    "```\n",
    "\n",
    "**The output from the Spacy Model Training**:\n",
    "\n",
    "```\n",
    "[2022-05-24 07:09:39,410] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev']\n",
    "ℹ Saving to output directory:\n",
    "../data/model_weights/spacy_small\n",
    "ℹ Using GPU: 0\n",
    "\n",
    "=========================== Initializing pipeline ===========================\n",
    "[2022-05-24 07:09:41,789] [INFO] Set up nlp object from config\n",
    "[2022-05-24 07:09:41,797] [DEBUG] Loading corpus from path: ../data/diease_ner/train_dev_test_split_spacy_binary/dev_data.spacy\n",
    "[2022-05-24 07:09:41,798] [DEBUG] Loading corpus from path: ../data/diease_ner/train_dev_test_split_spacy_binary/train_data.spacy\n",
    "[2022-05-24 07:09:41,798] [INFO] Pipeline: ['tok2vec', 'ner']\n",
    "[2022-05-24 07:09:41,803] [INFO] Created vocabulary\n",
    "[2022-05-24 07:09:41,804] [INFO] Finished initializing nlp object\n",
    "\n",
    "[2022-05-24 07:09:51,839] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
    "✔ Initialized pipeline\n",
    "\n",
    "============================= Training pipeline =============================\n",
    "[2022-05-24 07:09:51,852] [DEBUG] Loading corpus from path: ../data/diease_ner/train_dev_test_split_spacy_binary/dev_data.spacy\n",
    "[2022-05-24 07:09:51,853] [DEBUG] Loading corpus from path: ../data/diease_ner/train_dev_test_split_spacy_binary/train_data.spacy\n",
    "ℹ Pipeline: ['tok2vec', 'ner']\n",
    "ℹ Initial learn rate: 0.001\n",
    "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
    "---  ------  ------------  --------  ------  ------  ------  ------\n",
    "  0       0          0.00     41.00    0.31    0.33    0.29    0.00\n",
    "  0     200        195.83   1820.96   41.44   55.56   33.05    0.41             \n",
    "  0     400        106.20   1131.87   47.27   66.58   36.64    0.47             \n",
    "  0     600         64.99    969.69   74.94   77.17   72.84    0.75             \n",
    "  0     800         87.66   1096.80   74.39   76.96   71.98    0.74             \n",
    "  1    1000         82.51   1134.93   77.53   79.28   75.86    0.78             \n",
    "  1    1200        113.61   1122.73   80.73   82.36   79.17    0.81             \n",
    "  1    1400        128.84   1178.08   84.40   86.10   82.76    0.84             \n",
    "...   \n",
    " 26    5400        287.07    591.02   85.96   87.04   84.91    0.86             \n",
    " 27    5600        382.16    540.78   86.21   87.56   84.91    0.86             \n",
    " 28    5800        406.03    615.57   86.29   86.67   85.92    0.86             \n",
    "Epoch 29:   0%|                                         | 0/200 [00:00<?, ?it/s]✔ Saved pipeline to output directory\n",
    "../data/model_weights/spacy_small/model-last\n",
    "```\n",
    "\n",
    "**Command for Evaluating the Model Results**:\n",
    "\n",
    "```\n",
    "!python3 -m spacy evaluate $SPACY_SMALL_MODEL_DIR_GPU/model-best $SPACY_DATA_DIR/test_data.spacy \\\n",
    "--output $SPACY_SMALL_MODEL_DIR_GPU/model-best/spacy_small_model_evaluation.json \\\n",
    "--gpu-id 0\n",
    "```\n",
    "\n",
    "**Output of Evaluate Command** :\n",
    "\n",
    "```\n",
    "ℹ Using GPU: 0\n",
    "\n",
    "================================== Results ==================================\n",
    "\n",
    "TOK     -    \n",
    "NER P   89.75\n",
    "NER R   82.81\n",
    "NER F   86.14\n",
    "SPEED   20752\n",
    "\n",
    "\n",
    "=============================== NER (per type) ===============================\n",
    "\n",
    "              P       R       F\n",
    "DISEASE   89.75   82.81   86.14\n",
    "\n",
    "✔ Saved results to\n",
    "../data/model_weights/spacy_small/model-best/spacy_small_model_evaluation.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b859ca",
   "metadata": {},
   "source": [
    "### 5C. Train a Spacy Roberta Base ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f1ee47",
   "metadata": {},
   "source": [
    "**CLI command for Spacy Model Training**:\n",
    "\n",
    "```\n",
    "!python3 -m spacy train $CONFIG_DIR/original_trf_config.cfg \\\n",
    "--output $SPACY_ROBERTA_MODEL_DIR_GPU \\\n",
    "--paths.train $SPACY_DATA_DIR/train_data.spacy \\\n",
    "--paths.dev $SPACY_DATA_DIR/dev_data.spacy \\\n",
    "--verbose \\\n",
    "-g 0\n",
    "```\n",
    "\n",
    "**The output from the Spacy Model Training**:\n",
    "\n",
    "```\n",
    "\n",
    "[2022-05-24 07:44:08,351] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev']\n",
    "✔ Created output directory:\n",
    "../data/model_weights/spacy_roberta_base_\n",
    "ℹ Saving to output directory:\n",
    "../data/model_weights/spacy_roberta_base_\n",
    "ℹ Using GPU: 0\n",
    "\n",
    "=========================== Initializing pipeline ===========================\n",
    "[2022-05-24 07:44:11,169] [INFO] Set up nlp object from config\n",
    "[2022-05-24 07:44:11,178] [DEBUG] Loading corpus from path: ../data/diease_ner/train_dev_test_split_spacy_binary/dev_data.spacy\n",
    "[2022-05-24 07:44:11,180] [DEBUG] Loading corpus from path: ../data/diease_ner/train_dev_test_split_spacy_binary/train_data.spacy\n",
    "[2022-05-24 07:44:11,180] [INFO] Pipeline: ['transformer', 'ner']\n",
    "[2022-05-24 07:44:11,184] [INFO] Created vocabulary\n",
    "[2022-05-24 07:44:11,185] [INFO] Finished initializing nlp object\n",
    "\n",
    "[2022-05-24 07:44:22,286] [INFO] Initialized pipeline components: ['transformer', 'ner']\n",
    "✔ Initialized pipeline\n",
    "\n",
    "============================= Training pipeline =============================\n",
    "[2022-05-24 07:44:22,298] [DEBUG] Loading corpus from path: ../data/diease_ner/train_dev_test_split_spacy_binary/dev_data.spacy\n",
    "[2022-05-24 07:44:22,299] [DEBUG] Loading corpus from path: ../data/diease_ner/train_dev_test_split_spacy_binary/train_data.spacy\n",
    "ℹ Pipeline: ['transformer', 'ner']\n",
    "ℹ Initial learn rate: 0.0\n",
    "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
    "---  ------  -------------  --------  ------  ------  ------  ------\n",
    "  0       0        4392.55    285.04    0.21    0.17    0.29    0.00\n",
    "  1     200      126102.97  33471.51   84.94   81.78   88.36    0.85\n",
    "  3     400        1782.34   2642.55   89.50   90.83   88.22    0.90\n",
    "  5     600        1123.23   1596.50   90.69   89.06   92.39    0.91\n",
    "...\n",
    " 27    2800         153.06    176.41   90.94   90.35   91.52    0.91\n",
    " 29    3000         103.80    128.69   90.86   88.98   92.82    0.91\n",
    " 30    3200         121.04    141.70   91.47   90.56   92.39    0.91\n",
    " 32    3400          90.05    116.95   90.51   89.93   91.09    0.91\n",
    " 34    3600         111.25    131.25   91.12   90.15   92.10    0.91\n",
    " 36    3800          79.87     82.69   90.30   89.66   90.95    0.90\n",
    " 38    4000          82.07     82.97   90.97   90.01   91.95    0.91\n",
    "✔ Saved pipeline to output directory\n",
    "../data/model_weights/spacy_roberta_base_/model-last\n",
    "CPU times: user 11.1 s, sys: 2.78 s, total: 13.9 s\n",
    "Wall time: 22min 37s\n",
    "\n",
    "```\n",
    "\n",
    "**Command for Evaluating the Model Results**:\n",
    "\n",
    "```\n",
    "!python3 -m spacy evaluate $SPACY_SMALL_MODEL_DIR_GPU/model-best $SPACY_DATA_DIR/test_data.spacy \\\n",
    "--output $SPACY_SMALL_MODEL_DIR_GPU/model-best/spacy_small_model_evaluation.json \\\n",
    "--gpu-id 0\n",
    "```\n",
    "\n",
    "**Output of Evaluate Command** :\n",
    "\n",
    "```\n",
    "ℹ Using GPU: 0\n",
    "\n",
    "================================== Results ==================================\n",
    "\n",
    "TOK     -    \n",
    "NER P   88.61\n",
    "NER R   90.26\n",
    "NER F   89.43\n",
    "SPEED   12020\n",
    "\n",
    "\n",
    "=============================== NER (per type) ===============================\n",
    "\n",
    "              P       R       F\n",
    "DISEASE   88.61   90.26   89.43\n",
    "\n",
    "✔ Saved results to\n",
    "../data/model_weights/spacy_roberta_base_/model-best/spacy_roberta_base_evaluation.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8724f1d1",
   "metadata": {},
   "source": [
    "## 6. Evaluate the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66592194",
   "metadata": {},
   "source": [
    "### 6A. Comparing the entity-level F1-score of (1) Rules, (2) Spacy small and (3) Spacy Roberta-base model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bf35970",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('spacy_model_ner/results_of_the_models.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "948e3a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Rules_Model</th>\n",
       "      <td>39.85</td>\n",
       "      <td>2.21</td>\n",
       "      <td>28.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spacy_Small_Model</th>\n",
       "      <td>89.75</td>\n",
       "      <td>82.81</td>\n",
       "      <td>86.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spacy_Roberta_Base_Model</th>\n",
       "      <td>88.61</td>\n",
       "      <td>90.26</td>\n",
       "      <td>89.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Precision  Recall  F1_Score\n",
       "Rules_Model                   39.85    2.21     28.52\n",
       "Spacy_Small_Model             89.75   82.81     86.14\n",
       "Spacy_Roberta_Base_Model      88.61   90.26     89.43"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e566b1",
   "metadata": {},
   "source": [
    "## 7. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90500388",
   "metadata": {},
   "source": [
    "In this blog article, we have shown how to effectively build a NER model on unlabeled data. <br>\n",
    "- We have compared Rules NER, a Spacy Small NER and roberta-base NER models. \n",
    "- We found `roberta_base` model is having the highest F1 score of 89%.  \n",
    "- We can also ensemble results of `Spacy Small NER` and `Spacy Roberta Base NER` models.  \n",
    "- A digression from the scope of this article: There are umpteen good tools (paid mostly) aiding the annotation. Sometimes, for simple NER problem (like tagging only one entity like this `Disease NER`), even excel is good for annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebfd461",
   "metadata": {},
   "source": [
    "Main Source:\n",
    "- https://spacy.io/api/cli#evaluate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
